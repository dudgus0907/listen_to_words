1
00:00:00,240 --> 00:00:04,799
The worst thing that can happen to

2
00:00:03,040 --> 00:00:06,120
someone who's making anything in the

3
00:00:04,799 --> 00:00:08,480
world is

4
00:00:06,120 --> 00:00:10,880
apathy. You put something out and nobody

5
00:00:08,480 --> 00:00:12,400
cares. The second worst scenario is you

6
00:00:10,880 --> 00:00:14,160
put something out and everybody is very

7
00:00:12,400 --> 00:00:16,000
happy with it because that means there's

8
00:00:14,160 --> 00:00:18,640
nothing else left to do. When these are

9
00:00:16,000 --> 00:00:20,880
your most dedicated user, they have a

10
00:00:18,640 --> 00:00:23,119
thousand things to complain about. In AI

11
00:00:20,880 --> 00:00:24,960
especially, if you can do X, people now

12
00:00:23,119 --> 00:00:26,880
want to do Y. Unlike traditional

13
00:00:24,960 --> 00:00:29,039
products where you know okay this has

14
00:00:26,880 --> 00:00:31,279
feature A, B and C and this is how

15
00:00:29,039 --> 00:00:33,559
feature A interacts with feature B like

16
00:00:31,279 --> 00:00:36,239
you know the whole state with large

17
00:00:33,559 --> 00:00:37,840
models people can do anything in it.

18
00:00:36,239 --> 00:00:39,920
People can generate anime. People can

19
00:00:37,840 --> 00:00:42,719
generate videos of a tomato rolling down

20
00:00:39,920 --> 00:00:44,239
a hill. With large models you don't know

21
00:00:42,719 --> 00:00:46,640
what your users are going to do and

22
00:00:44,239 --> 00:00:48,239
there's no physical scenario in which

23
00:00:46,640 --> 00:00:49,399
you could test all the capabilities of

24
00:00:48,239 --> 00:00:52,879
the

25
00:00:49,399 --> 00:00:54,320
model. So you really have to see what

26
00:00:52,879 --> 00:00:57,120
people are doing with it, where it's

27
00:00:54,320 --> 00:00:57,120
succeeding, where it's

28
00:00:57,399 --> 00:01:02,160
failing. Hey, my name is Amed. I'm one

29
00:00:59,920 --> 00:01:03,840
of the co-founders and CEO of Luma AI.

30
00:01:02,160 --> 00:01:05,600
At Luma, we are building multimodal

31
00:01:03,840 --> 00:01:07,760
general intelligence and that starts

32
00:01:05,600 --> 00:01:10,240
with building world's best video models.

33
00:01:07,760 --> 00:01:12,960
We have so far raised $200 million from

34
00:01:10,240 --> 00:01:16,080
Andre and Horovitz, Amplify Partners,

35
00:01:12,960 --> 00:01:19,119
Matrix partners, Nvidia, AMD, as well as

36
00:01:16,080 --> 00:01:22,479
Amazon. Lumi is training models that are

37
00:01:19,119 --> 00:01:25,119
able to learn and generate video, audio,

38
00:01:22,479 --> 00:01:27,520
text all together. Our premise is that

39
00:01:25,119 --> 00:01:29,759
by building models that train like human

40
00:01:27,520 --> 00:01:31,759
brain, we will be able to not only

41
00:01:29,759 --> 00:01:34,560
generate worlds but actually solve the

42
00:01:31,759 --> 00:01:34,560
limitations of

43
00:01:36,840 --> 00:01:41,280
LLMs. I grew up in India. As a child

44
00:01:39,360 --> 00:01:43,119
growing up, I was mostly very deeply

45
00:01:41,280 --> 00:01:45,119
interested in in physics from from very

46
00:01:43,119 --> 00:01:46,720
early on. Actually I spent majority of

47
00:01:45,119 --> 00:01:49,280
my time honestly uh you know learning

48
00:01:46,720 --> 00:01:51,479
about advanced physics and trying to you

49
00:01:49,280 --> 00:01:53,840
know understand how the world works.

50
00:01:51,479 --> 00:01:55,600
Honestly I studied math and physics in

51
00:01:53,840 --> 00:01:57,439
college. I was about to go for a

52
00:01:55,600 --> 00:01:59,119
graduate school PhD in in physics.

53
00:01:57,439 --> 00:02:00,799
Around the same time I also started like

54
00:01:59,119 --> 00:02:02,799
building iOS apps. My first one was

55
00:02:00,799 --> 00:02:04,399
actually uh uh this one for solving

56
00:02:02,799 --> 00:02:07,399
differential equations got actually

57
00:02:04,399 --> 00:02:09,679
relatively popular uh in the app

58
00:02:07,399 --> 00:02:11,120
store. That was very interesting like

59
00:02:09,679 --> 00:02:13,120
you know once you make something that

60
00:02:11,120 --> 00:02:15,040
other people find useful doesn't matter

61
00:02:13,120 --> 00:02:16,959
large number or small number that really

62
00:02:15,040 --> 00:02:18,560
kind of changes you then a couple of my

63
00:02:16,959 --> 00:02:20,560
friends uh started a company I left to

64
00:02:18,560 --> 00:02:22,560
join them instead and as time has gone

65
00:02:20,560 --> 00:02:25,680
on a few of my friends uh their company

66
00:02:22,560 --> 00:02:27,280
was acquired by Apple at Apple I started

67
00:02:25,680 --> 00:02:29,280
working on this agent system called

68
00:02:27,280 --> 00:02:31,360
shortcuts or workflows when we shipped

69
00:02:29,280 --> 00:02:33,599
that I learned that there was this part

70
00:02:31,360 --> 00:02:35,120
of the world where in Apple where this

71
00:02:33,599 --> 00:02:36,640
new thing was being built some of my

72
00:02:35,120 --> 00:02:38,000
friends had gone there already and they

73
00:02:36,640 --> 00:02:40,000
got completely silent about what they

74
00:02:38,000 --> 00:02:41,360
were doing and it was this insane secret

75
00:02:40,000 --> 00:02:43,200
like if you don't want me to know

76
00:02:41,360 --> 00:02:44,160
anything don't tell me it's a secret. I

77
00:02:43,200 --> 00:02:46,400
really wanted to figure out what the

78
00:02:44,160 --> 00:02:47,920
hell was going on and turns out they

79
00:02:46,400 --> 00:02:50,480
were building this new thing called the

80
00:02:47,920 --> 00:02:52,879
vision pro. So I joined the team that

81
00:02:50,480 --> 00:02:55,840
was working on this really ambitious

82
00:02:52,879 --> 00:02:58,160
project for 3D capturing the world with

83
00:02:55,840 --> 00:02:59,680
vision pro. The idea was if you're

84
00:02:58,160 --> 00:03:02,319
wearing this thing we can take you

85
00:02:59,680 --> 00:03:05,360
anywhere because we have full control

86
00:03:02,319 --> 00:03:06,640
over what your eyes see. And this was

87
00:03:05,360 --> 00:03:07,920
really close to my heart because like

88
00:03:06,640 --> 00:03:09,680
you know anything that has to do

89
00:03:07,920 --> 00:03:12,080
anything with simulating reality that

90
00:03:09,680 --> 00:03:13,519
really draws me very close. I started to

91
00:03:12,080 --> 00:03:15,400
work on that project and I worked on

92
00:03:13,519 --> 00:03:17,680
that for about 3

93
00:03:15,400 --> 00:03:19,120
years. This was around also the time

94
00:03:17,680 --> 00:03:21,840
when huge things were happening in

95
00:03:19,120 --> 00:03:23,599
language model. In 2020 it like really

96
00:03:21,840 --> 00:03:26,000
hit me in the head because uh the two

97
00:03:23,599 --> 00:03:29,200
things came out. It was the Delhi paper

98
00:03:26,000 --> 00:03:30,959
uh from OpenAI and this paper for 3D

99
00:03:29,200 --> 00:03:32,959
instruction called Nerf neural radiance

100
00:03:30,959 --> 00:03:34,799
fields. And honestly like that was

101
00:03:32,959 --> 00:03:36,239
really interesting to me because all the

102
00:03:34,799 --> 00:03:37,840
things we were doing procedurally by

103
00:03:36,239 --> 00:03:39,519
writing like you know a handwritten code

104
00:03:37,840 --> 00:03:41,519
and for rendering and for for capturing

105
00:03:39,519 --> 00:03:45,519
and reconstruction if these two things

106
00:03:41,519 --> 00:03:47,120
work you can learn to represent the

107
00:03:45,519 --> 00:03:48,239
world you don't you don't need to do any

108
00:03:47,120 --> 00:03:49,920
rendering you don't need to like write

109
00:03:48,239 --> 00:03:52,120
any graphics algorithms and what Dali

110
00:03:49,920 --> 00:03:54,799
proved was that from

111
00:03:52,120 --> 00:03:56,959
nothing you can generate images you know

112
00:03:54,799 --> 00:04:00,000
that was a huge thing for me Nerf gave

113
00:03:56,959 --> 00:04:02,400
you like static 3D worlds and Dali gave

114
00:04:00,000 --> 00:04:04,400
you images But our world is extremely

115
00:04:02,400 --> 00:04:05,920
dynamic. There's like a lot of stuff

116
00:04:04,400 --> 00:04:08,400
happening right like you know we walk

117
00:04:05,920 --> 00:04:10,400
around cars move around clouds move all

118
00:04:08,400 --> 00:04:13,120
these kind of things. The question was

119
00:04:10,400 --> 00:04:15,040
how can we actually simulate that world?

120
00:04:13,120 --> 00:04:16,880
So I started experimenting with these

121
00:04:15,040 --> 00:04:18,400
things. All I did was really like you

122
00:04:16,880 --> 00:04:20,400
know experiment with these methods write

123
00:04:18,400 --> 00:04:22,560
all kinds of networks train them. In

124
00:04:20,400 --> 00:04:25,040
about like you know 3 months time I was

125
00:04:22,560 --> 00:04:28,639
extremely convinced that this is how

126
00:04:25,040 --> 00:04:31,440
most videos things humans see will be

127
00:04:28,639 --> 00:04:33,120
made. And at my work, I was doing all

128
00:04:31,440 --> 00:04:36,000
these traditional techniques, right? So

129
00:04:33,120 --> 00:04:37,280
my choices were stay at Apple, right?

130
00:04:36,000 --> 00:04:38,639
Try to convince this big giant

131
00:04:37,280 --> 00:04:40,240
organization that like, hey, this is the

132
00:04:38,639 --> 00:04:42,000
future and and that we should do this

133
00:04:40,240 --> 00:04:44,479
and that like, you know, I need $100

134
00:04:42,000 --> 00:04:46,240
million to actually do this or go find

135
00:04:44,479 --> 00:04:48,160
15, 20 of the most brilliant people on

136
00:04:46,240 --> 00:04:50,240
the planet who can actually do this for

137
00:04:48,160 --> 00:04:51,680
us. I tried this at Apple first like,

138
00:04:50,240 --> 00:04:56,320
yeah, this is not going to happen here.

139
00:04:51,680 --> 00:04:58,880
Uh, I left and we started Lumi in 2022.

140
00:04:56,320 --> 00:05:00,639
In 2023, we built a 3D generative model

141
00:04:58,880 --> 00:05:02,800
actually called Genie. At that time,

142
00:05:00,639 --> 00:05:04,320
large scale infrastructure for training

143
00:05:02,800 --> 00:05:06,400
and coders and things like that didn't

144
00:05:04,320 --> 00:05:08,240
exist. So, we had to build and invent

145
00:05:06,400 --> 00:05:10,320
all these pieces basically. So, we

146
00:05:08,240 --> 00:05:12,000
started that work. We built a lot lot of

147
00:05:10,320 --> 00:05:13,520
large scale data collection systems,

148
00:05:12,000 --> 00:05:14,960
large scale training systems, all those

149
00:05:13,520 --> 00:05:16,720
kind of things. It took us about a year,

150
00:05:14,960 --> 00:05:18,560
year and a half actually. We started the

151
00:05:16,720 --> 00:05:20,240
work on the first video model that Luma

152
00:05:18,560 --> 00:05:21,840
had released in 2024 called Dream

153
00:05:20,240 --> 00:05:23,360
Machine. At that time, our chief

154
00:05:21,840 --> 00:05:24,800
scientist Jaing had joined our team,

155
00:05:23,360 --> 00:05:26,400
right? like you know Xiaaming was a

156
00:05:24,800 --> 00:05:28,560
leading image and video generation at

157
00:05:26,400 --> 00:05:29,840
Nvidia. At the time these new graphics

158
00:05:28,560 --> 00:05:30,960
cards were coming about or these new

159
00:05:29,840 --> 00:05:33,280
training chips were coming about from

160
00:05:30,960 --> 00:05:34,720
Nvidia H100s. When we looked at that for

161
00:05:33,280 --> 00:05:36,400
the first time we were like okay the

162
00:05:34,720 --> 00:05:37,919
cards are capable enough the chips are

163
00:05:36,400 --> 00:05:40,000
capable enough I think we can gather

164
00:05:37,919 --> 00:05:41,600
enough data and the algorithms are there

165
00:05:40,000 --> 00:05:42,960
from our previous work on 3D generative

166
00:05:41,600 --> 00:05:45,000
models and things like that that we can

167
00:05:42,960 --> 00:05:48,080
actually do this. So we started that

168
00:05:45,000 --> 00:05:50,720
process and it took us like you know

169
00:05:48,080 --> 00:05:51,919
about five or six months actually about

170
00:05:50,720 --> 00:05:54,560
four and a half months to be honest with

171
00:05:51,919 --> 00:05:55,759
you to go from this first place where we

172
00:05:54,560 --> 00:05:57,680
had some of the infrastructure and

173
00:05:55,759 --> 00:05:59,120
things like that to training a proper

174
00:05:57,680 --> 00:06:02,080
model that we could actually release to

175
00:05:59,120 --> 00:06:04,240
the world but it came after a year year

176
00:06:02,080 --> 00:06:05,440
and a half of work on encoders of

177
00:06:04,240 --> 00:06:06,720
learning models of building

178
00:06:05,440 --> 00:06:10,080
infrastructure all those kind of things

179
00:06:06,720 --> 00:06:12,319
so it was also at the heels of open sora

180
00:06:10,080 --> 00:06:13,759
so open had announced sora in February

181
00:06:12,319 --> 00:06:16,080
and that was actually really interesting

182
00:06:13,759 --> 00:06:17,360
Because you know before Sora our video

183
00:06:16,080 --> 00:06:18,720
efforts were a little bit smaller

184
00:06:17,360 --> 00:06:20,479
because we were very small company at

185
00:06:18,720 --> 00:06:22,479
the time. We were barely uh we were

186
00:06:20,479 --> 00:06:23,759
barely like 20 people. We had good

187
00:06:22,479 --> 00:06:25,840
amount of compute but we didn't have

188
00:06:23,759 --> 00:06:27,680
anywhere open AI level of compute. So we

189
00:06:25,840 --> 00:06:29,600
could not have scaled it without knowing

190
00:06:27,680 --> 00:06:31,120
that oh scaling could work. Once that

191
00:06:29,600 --> 00:06:33,639
evidence was in front of us like we just

192
00:06:31,120 --> 00:06:36,160
scaled our efforts significantly at that

193
00:06:33,639 --> 00:06:37,919
point. 3 months later we had uh the

194
00:06:36,160 --> 00:06:39,360
first dream machine model which was

195
00:06:37,919 --> 00:06:41,120
really funny. It was like very first

196
00:06:39,360 --> 00:06:43,199
early model. Today you wouldn't consider

197
00:06:41,120 --> 00:06:46,080
that to be very good, right? But at that

198
00:06:43,199 --> 00:06:47,600
time that was huge and got so popular.

199
00:06:46,080 --> 00:06:50,000
It was on Good Morning America. It was

200
00:06:47,600 --> 00:06:51,919
on CNN and then people were absolutely

201
00:06:50,000 --> 00:06:53,759
astonished and mesmerized by it like oh

202
00:06:51,919 --> 00:06:55,840
you can generate video. So that made

203
00:06:53,759 --> 00:06:58,000
Luma into a very well-known household

204
00:06:55,840 --> 00:07:01,280
name at that time and then now and gave

205
00:06:58,000 --> 00:07:02,720
us you know all the resources we need to

206
00:07:01,280 --> 00:07:03,680
continue our research to continue our

207
00:07:02,720 --> 00:07:05,800
work. So yeah that was the first

208
00:07:03,680 --> 00:07:08,160
streaming machine. Whenever you're

209
00:07:05,800 --> 00:07:09,599
developing a new capability into the

210
00:07:08,160 --> 00:07:12,080
world, when you're developing a new

211
00:07:09,599 --> 00:07:14,319
technology, oh man, it never worked the

212
00:07:12,080 --> 00:07:16,479
first try. It never worked the 10th try.

213
00:07:14,319 --> 00:07:19,199
I would really say if you have found a

214
00:07:16,479 --> 00:07:21,280
good market and you want to find what

215
00:07:19,199 --> 00:07:23,199
fits into that market, iterate like

216
00:07:21,280 --> 00:07:26,080
hell. Anything that slows down your

217
00:07:23,199 --> 00:07:27,680
iteration velocity, avoid. If you're an

218
00:07:26,080 --> 00:07:28,880
engineering mindset like myself, you

219
00:07:27,680 --> 00:07:30,960
want to like, you know, build a very

220
00:07:28,880 --> 00:07:32,319
stable system, right? Extensible system

221
00:07:30,960 --> 00:07:33,440
with like, you know, all all good

222
00:07:32,319 --> 00:07:34,880
technologies and all these kind of

223
00:07:33,440 --> 00:07:37,199
things. But sometimes those systems

224
00:07:34,880 --> 00:07:38,639
really slow you down because you you

225
00:07:37,199 --> 00:07:40,000
build this monolith and it's good. It's

226
00:07:38,639 --> 00:07:41,840
very scalable. It's all the things

227
00:07:40,000 --> 00:07:43,440
right. But the problem is to change one

228
00:07:41,840 --> 00:07:45,599
thing you need to now change like you

229
00:07:43,440 --> 00:07:48,319
know five modules compared to that just

230
00:07:45,599 --> 00:07:49,599
a barebones thing you built in Python

231
00:07:48,319 --> 00:07:51,360
and like you know you just put it up

232
00:07:49,599 --> 00:07:53,360
there. You have no allegiance to it.

233
00:07:51,360 --> 00:07:55,039
It's already so you don't care. You

234
00:07:53,360 --> 00:07:56,639
just iterate. You change it all day all

235
00:07:55,039 --> 00:08:00,520
night right? Like you know and I think

236
00:07:56,639 --> 00:08:00,520
that's really really important.

237
00:08:00,879 --> 00:08:05,520
This episode is sponsored by Atio, the

238
00:08:03,280 --> 00:08:07,919
AI native CRM for the next era of

239
00:08:05,520 --> 00:08:10,080
companies. Connect your email and ATIO

240
00:08:07,919 --> 00:08:12,560
instantly builds your CRM right before

241
00:08:10,080 --> 00:08:14,639
your eyes with every company contact and

242
00:08:12,560 --> 00:08:17,120
interaction you've ever had enriched and

243
00:08:14,639 --> 00:08:19,280
organized. That's ATIO. And here's what

244
00:08:17,120 --> 00:08:21,440
makes it even more game-changing. You

245
00:08:19,280 --> 00:08:23,440
can build AI powered automations and use

246
00:08:21,440 --> 00:08:25,599
its research agents to tackle some of

247
00:08:23,440 --> 00:08:27,440
your most complex business processes,

248
00:08:25,599 --> 00:08:30,080
freeing you to focus on what matters

249
00:08:27,440 --> 00:08:31,680
most, building your company. Join

250
00:08:30,080 --> 00:08:34,240
thousands of companies who are already

251
00:08:31,680 --> 00:08:36,000
using Atio to power their businesses.

252
00:08:34,240 --> 00:08:39,839
Visit the link in the description to

253
00:08:36,000 --> 00:08:39,839
begin your 2e free trial with

254
00:08:44,600 --> 00:08:50,080
Atio. The dream machine created by tech

255
00:08:47,839 --> 00:08:52,640
company Luma featuring a new tool that

256
00:08:50,080 --> 00:08:54,560
lets users turn images into video.

257
00:08:52,640 --> 00:08:56,160
Honestly, we thought not many people

258
00:08:54,560 --> 00:08:58,320
will try it because you know it's a

259
00:08:56,160 --> 00:08:59,920
really new thing. We know eventually the

260
00:08:58,320 --> 00:09:01,040
demand will be huge but initially we

261
00:08:59,920 --> 00:09:02,800
thought like you know not many people

262
00:09:01,040 --> 00:09:04,560
would try it but man the number of

263
00:09:02,800 --> 00:09:06,560
people that tried it was insane. So we

264
00:09:04,560 --> 00:09:08,320
put some pricing on it. It was only

265
00:09:06,560 --> 00:09:09,760
because I was like okay well let's see

266
00:09:08,320 --> 00:09:11,519
you know how much are people willing to

267
00:09:09,760 --> 00:09:13,360
pay for it. So I had this extremely

268
00:09:11,519 --> 00:09:15,279
unscientific way. Let's make it really

269
00:09:13,360 --> 00:09:17,040
expensive like you know we'll give a

270
00:09:15,279 --> 00:09:19,360
small number of videos for free and then

271
00:09:17,040 --> 00:09:21,519
it will be 30 bucks and then 100 bucks

272
00:09:19,360 --> 00:09:24,160
and then 500 bucks and the reason was

273
00:09:21,519 --> 00:09:25,680
solely to discover customer bases

274
00:09:24,160 --> 00:09:28,320
discover who is willing to pay for it

275
00:09:25,680 --> 00:09:29,839
because if someone is willing to pay $30

276
00:09:28,320 --> 00:09:31,920
they are getting something out of it if

277
00:09:29,839 --> 00:09:33,600
someone is willing to pay $100 they're

278
00:09:31,920 --> 00:09:34,959
clearly making money from it and if

279
00:09:33,600 --> 00:09:36,399
someone is willing to pay 500 bucks

280
00:09:34,959 --> 00:09:37,839
right I need to go talk to them because

281
00:09:36,399 --> 00:09:40,240
I need to understand well why are you

282
00:09:37,839 --> 00:09:42,560
paying so much per month to to use this

283
00:09:40,240 --> 00:09:44,160
product so we took the approach of

284
00:09:42,560 --> 00:09:45,519
putting something out there in very

285
00:09:44,160 --> 00:09:47,120
unpolished state. If someone found it

286
00:09:45,519 --> 00:09:48,880
valuable, we would know a lot, we would

287
00:09:47,120 --> 00:09:50,160
learn a lot and we did. Uh so this was

288
00:09:48,880 --> 00:09:52,240
one of the people who were paying like

289
00:09:50,160 --> 00:09:53,839
100 or 500 bucks. I was curious what are

290
00:09:52,240 --> 00:09:55,600
they doing with this thing. I got on the

291
00:09:53,839 --> 00:09:57,839
call and and like you know this person

292
00:09:55,600 --> 00:09:59,680
was um very happy grinning like you know

293
00:09:57,839 --> 00:10:02,080
uh ear to ear at that time and they were

294
00:09:59,680 --> 00:10:03,000
like oh I'm really great to meet you and

295
00:10:02,080 --> 00:10:05,839
I was

296
00:10:03,000 --> 00:10:07,200
like is that you? They're well known

297
00:10:05,839 --> 00:10:08,640
especially if you know like the art

298
00:10:07,200 --> 00:10:10,480
directors and and like you know people

299
00:10:08,640 --> 00:10:12,000
in the world who make movies. What I

300
00:10:10,480 --> 00:10:14,240
learned was that they were trying to

301
00:10:12,000 --> 00:10:16,000
create this scene in one of the more

302
00:10:14,240 --> 00:10:17,279
famous movies, right? They weren't able

303
00:10:16,000 --> 00:10:19,360
to do that with their traditional

304
00:10:17,279 --> 00:10:21,279
techniques. They tried Dream Machine and

305
00:10:19,360 --> 00:10:23,440
they got a really great scene out in

306
00:10:21,279 --> 00:10:24,880
like 30 minutes and now this person was

307
00:10:23,440 --> 00:10:27,200
talking to me because they were asking

308
00:10:24,880 --> 00:10:29,279
me to release the rights so that they

309
00:10:27,200 --> 00:10:31,279
could use it in the movie and I was just

310
00:10:29,279 --> 00:10:32,720
blown away. First version of the model

311
00:10:31,279 --> 00:10:35,440
like it was not good enough to be used

312
00:10:32,720 --> 00:10:37,279
in movies generally like really it

313
00:10:35,440 --> 00:10:39,040
wasn't. But here was someone who

314
00:10:37,279 --> 00:10:41,680
actually found even that useful early

315
00:10:39,040 --> 00:10:42,880
days. Put it out. Talk to your users.

316
00:10:41,680 --> 00:10:44,399
See what they're doing, what they're not

317
00:10:42,880 --> 00:10:46,000
doing. Talk to them like, "Hey, how are

318
00:10:44,399 --> 00:10:47,279
you using our stuff? If you're not using

319
00:10:46,000 --> 00:10:48,720
our stuff, how are you not using our

320
00:10:47,279 --> 00:10:50,079
stuff?" Right? Do you know about our

321
00:10:48,720 --> 00:10:52,079
stuff? How did you find out? How did you

322
00:10:50,079 --> 00:10:54,240
not find out? We have a group of about

323
00:10:52,079 --> 00:10:57,040
like, you know, 2,000 3,000 of our most

324
00:10:54,240 --> 00:10:58,959
engaged users in Discord. Myself, but

325
00:10:57,040 --> 00:11:01,680
also our research team, our product

326
00:10:58,959 --> 00:11:04,720
team, our engineers, they're all in that

327
00:11:01,680 --> 00:11:06,240
chat all day. When these are your most

328
00:11:04,720 --> 00:11:07,440
dedicated users, right, like you know,

329
00:11:06,240 --> 00:11:09,079
paying users, people who are like, you

330
00:11:07,440 --> 00:11:11,519
know, spending a lot of time on your

331
00:11:09,079 --> 00:11:14,480
platform, they have a thousand things to

332
00:11:11,519 --> 00:11:17,279
complain about and that's very good. The

333
00:11:14,480 --> 00:11:20,040
worst thing that can happen to someone

334
00:11:17,279 --> 00:11:22,600
who's making anything in the world is

335
00:11:20,040 --> 00:11:25,120
apathy. You put something out and nobody

336
00:11:22,600 --> 00:11:26,880
cares. That's the worst scenario. The

337
00:11:25,120 --> 00:11:28,240
second worst scenario is you put

338
00:11:26,880 --> 00:11:30,640
something out and everybody is very

339
00:11:28,240 --> 00:11:32,320
happy with it because that means there's

340
00:11:30,640 --> 00:11:33,920
nothing else left to do. Generally, if

341
00:11:32,320 --> 00:11:36,079
everybody's just really telling you all

342
00:11:33,920 --> 00:11:38,880
good things about it, that probably

343
00:11:36,079 --> 00:11:40,560
means they just want to interview you or

344
00:11:38,880 --> 00:11:42,480
or they're lying to you. Unlike

345
00:11:40,560 --> 00:11:44,640
traditional products where you know,

346
00:11:42,480 --> 00:11:46,399
okay, this has feature A, B, and C, and

347
00:11:44,640 --> 00:11:49,040
this is how feature A interacts with

348
00:11:46,399 --> 00:11:51,760
feature B, like you know the whole state

349
00:11:49,040 --> 00:11:53,760
very well, with large models, people can

350
00:11:51,760 --> 00:11:55,760
do anything with it. People can generate

351
00:11:53,760 --> 00:11:57,880
anime, people can generate videos of a

352
00:11:55,760 --> 00:12:00,000
tomato rolling down a hill. With large

353
00:11:57,880 --> 00:12:02,720
models, you don't know what your users

354
00:12:00,000 --> 00:12:04,640
are going to do. And there's no physical

355
00:12:02,720 --> 00:12:07,040
scenario in which you could test all the

356
00:12:04,640 --> 00:12:08,639
capabilities of the model. So you really

357
00:12:07,040 --> 00:12:12,240
have to see what people are doing with

358
00:12:08,639 --> 00:12:12,240
it, where it's succeeding, where it's

359
00:12:14,440 --> 00:12:18,240
failing. We are not a video model

360
00:12:16,720 --> 00:12:21,279
company. We are not building video

361
00:12:18,240 --> 00:12:26,639
models or image models. We our goal is

362
00:12:21,279 --> 00:12:26,639
very simply to solve multimodal general

363
00:12:27,320 --> 00:12:32,480
intelligence. What does that mean? Our

364
00:12:29,680 --> 00:12:33,680
belief is that people don't want image

365
00:12:32,480 --> 00:12:35,959
generation models or video generation

366
00:12:33,680 --> 00:12:38,240
models. What people want are

367
00:12:35,959 --> 00:12:39,839
worldbuilders. Every video, every movie

368
00:12:38,240 --> 00:12:41,360
is a world, a universe that like, you

369
00:12:39,839 --> 00:12:42,639
know, someone created. Whether you're

370
00:12:41,360 --> 00:12:44,240
talking about high fantasy like Lord of

371
00:12:42,639 --> 00:12:46,240
the Rings for instance, that's a whole

372
00:12:44,240 --> 00:12:47,920
universe with different laws of physics

373
00:12:46,240 --> 00:12:49,360
with like you know different characters,

374
00:12:47,920 --> 00:12:50,720
their their personalities, all these

375
00:12:49,360 --> 00:12:52,720
things. Or if you think about a YouTube

376
00:12:50,720 --> 00:12:54,480
video or Tik Tok, they they create a

377
00:12:52,720 --> 00:12:57,440
personality, a persona, all these kind

378
00:12:54,480 --> 00:12:58,839
of things. We need models that let

379
00:12:57,440 --> 00:13:02,560
people

380
00:12:58,839 --> 00:13:03,839
create worlds and then hit play. For

381
00:13:02,560 --> 00:13:05,760
that, you need to build a very different

382
00:13:03,839 --> 00:13:08,480
kind of intelligence. To build that kind

383
00:13:05,760 --> 00:13:10,639
of intelligence, text alone is just not

384
00:13:08,480 --> 00:13:14,240
enough. Think about the way humans learn

385
00:13:10,639 --> 00:13:16,399
a concept. We see it with our eyes and

386
00:13:14,240 --> 00:13:18,399
video. We hear about it with our ears

387
00:13:16,399 --> 00:13:20,240
and we reason about it logically in

388
00:13:18,399 --> 00:13:22,160
text. Everything humans learn from day

389
00:13:20,240 --> 00:13:23,680
in and day out doesn't just happen in

390
00:13:22,160 --> 00:13:27,079
text. It happens in all these

391
00:13:23,680 --> 00:13:29,600
modalities. So if you want to build

392
00:13:27,079 --> 00:13:32,480
intelligence that can collaborate with

393
00:13:29,600 --> 00:13:34,959
humans digitally and physically that can

394
00:13:32,480 --> 00:13:37,160
understand us that can entertain us you

395
00:13:34,959 --> 00:13:39,839
need to build intelligence that is

396
00:13:37,160 --> 00:13:43,120
trained on all the data human brain is

397
00:13:39,839 --> 00:13:46,000
trained on right so video is a big part

398
00:13:43,120 --> 00:13:47,680
of that so we believe that multimodal

399
00:13:46,000 --> 00:13:50,680
intelligence or multimodal data actually

400
00:13:47,680 --> 00:13:53,279
is on the critical path to

401
00:13:50,680 --> 00:13:54,959
AGI when you're working on a problem

402
00:13:53,279 --> 00:13:56,560
that is worth solving doing that really

403
00:13:54,959 --> 00:13:58,519
motivates you. I find anything

404
00:13:56,560 --> 00:14:00,880
interesting but finding something

405
00:13:58,519 --> 00:14:02,880
interesting and finding something you

406
00:14:00,880 --> 00:14:04,560
are just so mad about like you know that

407
00:14:02,880 --> 00:14:07,040
you want to do it right it's very

408
00:14:04,560 --> 00:14:09,120
different passion could be a moment in

409
00:14:07,040 --> 00:14:10,560
time and it can come and go oh this

410
00:14:09,120 --> 00:14:11,760
problem it would be so great if you

411
00:14:10,560 --> 00:14:13,199
could do that and you can imagine that

412
00:14:11,760 --> 00:14:15,040
oh I'm going to spend all my life doing

413
00:14:13,199 --> 00:14:16,959
it generally that's not the case my

414
00:14:15,040 --> 00:14:19,279
suggestion would be really try a lot of

415
00:14:16,959 --> 00:14:21,920
things and try to go deep into them and

416
00:14:19,279 --> 00:14:23,440
what you want to find is not that you

417
00:14:21,920 --> 00:14:25,519
were interested in the depth of the

418
00:14:23,440 --> 00:14:27,680
problem but whether that depth gets gets

419
00:14:25,519 --> 00:14:29,279
you more excited or less excited. When

420
00:14:27,680 --> 00:14:30,800
you go deep into it, you have to put

421
00:14:29,279 --> 00:14:32,320
effort. Sometimes when you're putting

422
00:14:30,800 --> 00:14:35,680
effort into like, oh, this is as boring

423
00:14:32,320 --> 00:14:37,199
as it gets, right? Don't do that. If you

424
00:14:35,680 --> 00:14:39,519
found something, when when then it gets

425
00:14:37,199 --> 00:14:42,240
harder, you get more excited about that,

426
00:14:39,519 --> 00:14:43,760
right? That's a unique thing. Honestly,

427
00:14:42,240 --> 00:14:46,639
I can guarantee you that most people

428
00:14:43,760 --> 00:14:48,880
around you will just quit. Try a lot of

429
00:14:46,639 --> 00:14:50,880
things. Try to go deep into them and try

430
00:14:48,880 --> 00:14:52,720
to see, can you stay excited, not

431
00:14:50,880 --> 00:14:54,480
artificially, even after you're you're

432
00:14:52,720 --> 00:14:56,079
done thinking about that problem, right?

433
00:14:54,480 --> 00:14:57,920
you know but you can't stop thinking

434
00:14:56,079 --> 00:15:00,240
about that problem like it comes to you

435
00:14:57,920 --> 00:15:01,519
at night it comes to you like oh but how

436
00:15:00,240 --> 00:15:04,079
do I do that right like you know that

437
00:15:01,519 --> 00:15:06,800
kind of thing if you can find that and

438
00:15:04,079 --> 00:15:08,480
somehow magically or or luckily that

439
00:15:06,800 --> 00:15:13,399
happens to also be an opportunity in

440
00:15:08,480 --> 00:15:13,399
which a company can be built that's it

441
00:15:19,690 --> 00:15:22,769
[Music]

