1
00:00:00,080 --> 00:00:04,720
I've always been jealous of Winston

2
00:00:02,200 --> 00:00:06,640
Churchill. There's a quote, by the way,

3
00:00:04,720 --> 00:00:09,040
the history of innovation is the bed,

4
00:00:06,640 --> 00:00:10,880
the bus, and the bathtub. It's always

5
00:00:09,040 --> 00:00:12,559
these moments when we're not really

6
00:00:10,880 --> 00:00:14,160
thinking about work or we're kind of

7
00:00:12,559 --> 00:00:16,560
doing something else that good ideas

8
00:00:14,160 --> 00:00:18,720
come to us. Winston Churchill, he's

9
00:00:16,560 --> 00:00:20,880
sitting in the bathtub and he's

10
00:00:18,720 --> 00:00:22,720
dictating a national address to his

11
00:00:20,880 --> 00:00:24,880
assistant who's in the other room. She's

12
00:00:22,720 --> 00:00:26,560
saying, "Distinguished ladies and

13
00:00:24,880 --> 00:00:28,720
gentlemen, don't call them

14
00:00:26,560 --> 00:00:30,480
distinguished. They're not just, this is

15
00:00:28,720 --> 00:00:33,520
the Gary Oldman version, they're not

16
00:00:30,480 --> 00:00:35,520
distinguished, you know, dear ladies and

17
00:00:33,520 --> 00:00:38,559
gentlemen, we have gathered together.

18
00:00:35,520 --> 00:00:41,040
Get to the point, you know, and I'm

19
00:00:38,559 --> 00:00:43,040
watching this going, I would give

20
00:00:41,040 --> 00:00:46,079
anything to have an assistant who

21
00:00:43,040 --> 00:00:48,399
understood my context and my voice and

22
00:00:46,079 --> 00:00:50,000
my intent well enough that I could sit

23
00:00:48,399 --> 00:00:53,879
in the bath and they could write my

24
00:00:50,000 --> 00:00:56,879
speech. Now, the poorest villager in

25
00:00:53,879 --> 00:00:59,359
PaloAlto can have what only Winston

26
00:00:56,879 --> 00:01:01,920
Churchill used to have, which is an

27
00:00:59,359 --> 00:01:04,720
assistant that has my context and my

28
00:01:01,920 --> 00:01:07,119
voice and my intent available to me so

29
00:01:04,720 --> 00:01:10,479
that when I'm in the bathtub, I can be

30
00:01:07,119 --> 00:01:14,520
dictating my address. That is absolutely

31
00:01:10,479 --> 00:01:14,520
technically possible today.

32
00:01:14,910 --> 00:01:18,090
[Music]

33
00:01:20,799 --> 00:01:25,759
I'm Jeremy Utley. I am an adjunct

34
00:01:22,640 --> 00:01:27,520
professor of creativity and AI at

35
00:01:25,759 --> 00:01:30,000
Stanford University. I've been teaching

36
00:01:27,520 --> 00:01:32,400
at Stanford for the last 15 years at the

37
00:01:30,000 --> 00:01:34,560
intersection of creativity, innovation,

38
00:01:32,400 --> 00:01:36,640
entrepreneurship, and now increasingly

39
00:01:34,560 --> 00:01:39,240
artificial intelligence. The topic that

40
00:01:36,640 --> 00:01:42,079
I'm most focused on right now is helping

41
00:01:39,240 --> 00:01:45,399
non-technical professionals learn to be

42
00:01:42,079 --> 00:01:48,720
good collaborators to or with generative

43
00:01:45,399 --> 00:01:50,960
AI. And then two years ago, myself and

44
00:01:48,720 --> 00:01:52,799
my partner at the time, Perry Claybond,

45
00:01:50,960 --> 00:01:55,680
wrote a book called Idea Flow, which was

46
00:01:52,799 --> 00:01:58,399
the canonical book on idea generation

47
00:01:55,680 --> 00:02:00,399
and prototyping. So super proud of that.

48
00:01:58,399 --> 00:02:02,640
It was the culmination of a dozen years

49
00:02:00,399 --> 00:02:04,399
of leading executive programs and the

50
00:02:02,640 --> 00:02:06,479
leadership program and the

51
00:02:04,399 --> 00:02:09,200
entrepreneurship program at Stanford.

52
00:02:06,479 --> 00:02:10,840
And one month after our book came out,

53
00:02:09,200 --> 00:02:14,400
Chad GBT came

54
00:02:10,840 --> 00:02:17,280
out. To me, the fact that I wrote the

55
00:02:14,400 --> 00:02:19,840
canonical book on idea generation, just

56
00:02:17,280 --> 00:02:23,360
prior to AI is like writing the best

57
00:02:19,840 --> 00:02:26,959
book on retail just before the internet.

58
00:02:23,360 --> 00:02:28,720
AI is a tool to dramatically augment and

59
00:02:26,959 --> 00:02:30,879
amplify our creativity. And the truth

60
00:02:28,720 --> 00:02:33,040
is, I didn't know a lot about it when

61
00:02:30,879 --> 00:02:35,280
the book came out. So, one month after

62
00:02:33,040 --> 00:02:38,160
my book came out, instead of going on a

63
00:02:35,280 --> 00:02:40,800
world book tour, I strapped myself back

64
00:02:38,160 --> 00:02:42,720
into the front row as a student and

65
00:02:40,800 --> 00:02:44,879
said, I need to be learning about this

66
00:02:42,720 --> 00:02:46,720
transformative new technology. So, I

67
00:02:44,879 --> 00:02:48,239
started taking classes. I started

68
00:02:46,720 --> 00:02:51,200
conducting research. which I started

69
00:02:48,239 --> 00:02:53,040
work working with and studying teams

70
00:02:51,200 --> 00:02:55,840
inside of organizations using the tool

71
00:02:53,040 --> 00:02:59,360
to understand the simple question how

72
00:02:55,840 --> 00:03:02,000
does generative AI impact the individual

73
00:02:59,360 --> 00:03:05,200
and the team and the organization's

74
00:03:02,000 --> 00:03:05,200
ability to solve

75
00:03:05,879 --> 00:03:11,640
problems. You can give an AI a prompt.

76
00:03:09,040 --> 00:03:15,200
For example, how should I answer this

77
00:03:11,640 --> 00:03:17,760
question? Or you could give an AI the

78
00:03:15,200 --> 00:03:19,760
question, I want to ask how I should

79
00:03:17,760 --> 00:03:22,959
answer this question. What's the best

80
00:03:19,760 --> 00:03:25,840
way of framing that question to an AI?

81
00:03:22,959 --> 00:03:28,560
So, you see what I did there? I asked AI

82
00:03:25,840 --> 00:03:31,680
for how to ask AI my question. But you

83
00:03:28,560 --> 00:03:34,080
can use AI to use AI, which is you

84
00:03:31,680 --> 00:03:35,519
couldn't use Excel to use Excel.

85
00:03:34,080 --> 00:03:37,360
PowerPoint can't teach you how to use

86
00:03:35,519 --> 00:03:40,159
PowerPoint. Email can't teach you how to

87
00:03:37,360 --> 00:03:42,319
use email. AI strangely can teach you

88
00:03:40,159 --> 00:03:44,560
how to use itself. If you think to ask,

89
00:03:42,319 --> 00:03:46,799
go to your language model of choice and

90
00:03:44,560 --> 00:03:50,879
just say the following. Hey, you're an

91
00:03:46,799 --> 00:03:53,280
AI expert. I would love your help and a

92
00:03:50,879 --> 00:03:56,319
consultation with you to help me figure

93
00:03:53,280 --> 00:03:59,200
out where I can best leverage AI in my

94
00:03:56,319 --> 00:04:01,040
life. As an AI expert, would you please

95
00:03:59,200 --> 00:04:02,799
ask me questions, one question at a

96
00:04:01,040 --> 00:04:04,799
time, until you have enough context

97
00:04:02,799 --> 00:04:07,840
about my workflows and responsibilities

98
00:04:04,799 --> 00:04:11,000
and KPIs and objectives that you could

99
00:04:07,840 --> 00:04:13,280
make to obvious recommendations and two

100
00:04:11,000 --> 00:04:16,000
nonobvious recommendations for how I

101
00:04:13,280 --> 00:04:18,239
could leverage AI in my work. You will

102
00:04:16,000 --> 00:04:19,919
have one of the most enlightening and

103
00:04:18,239 --> 00:04:22,079
illuminating conversations you've ever

104
00:04:19,919 --> 00:04:24,800
had. And it's all because of AI's

105
00:04:22,079 --> 00:04:27,520
ability to evaluate its own work. What

106
00:04:24,800 --> 00:04:29,440
I've seen is non-technical employees are

107
00:04:27,520 --> 00:04:31,199
able to do incredible things. Here's one

108
00:04:29,440 --> 00:04:33,280
example. The National Park Service

109
00:04:31,199 --> 00:04:35,120
called me and asked me if I would

110
00:04:33,280 --> 00:04:37,680
conduct a training program for a bunch

111
00:04:35,120 --> 00:04:40,240
of backcountry rangers. So, they

112
00:04:37,680 --> 00:04:42,720
gathered a group of about 60 backcountry

113
00:04:40,240 --> 00:04:44,639
rangers and facilities managers into a

114
00:04:42,720 --> 00:04:47,199
training session. And I spent a couple

115
00:04:44,639 --> 00:04:50,240
of hours over Zoom teaching folks the

116
00:04:47,199 --> 00:04:52,400
basics of collaborating with AI. One of

117
00:04:50,240 --> 00:04:54,240
the people in that session was a

118
00:04:52,400 --> 00:04:56,400
gentleman named Adam Rhymer who works at

119
00:04:54,240 --> 00:04:58,880
Glen Canyon National Park. And one of

120
00:04:56,400 --> 00:05:01,280
the things I say is you should focus on

121
00:04:58,880 --> 00:05:03,040
parts of your work that you dread, parts

122
00:05:01,280 --> 00:05:05,360
of your work that you don't enjoy, that

123
00:05:03,040 --> 00:05:07,600
you think, h I have to do this again.

124
00:05:05,360 --> 00:05:09,680
And Adam said, if I have to replace the

125
00:05:07,600 --> 00:05:11,360
carpet tiles in the lodge, I have to

126
00:05:09,680 --> 00:05:13,120
fill out all of this paperwork. And so

127
00:05:11,360 --> 00:05:16,000
to replace a carpet tile will sometimes

128
00:05:13,120 --> 00:05:18,080
take 2 or 3 days of paperwork. Then he

129
00:05:16,000 --> 00:05:21,600
thought, could AI help me write that

130
00:05:18,080 --> 00:05:25,120
paperwork? And in 45 minutes, he built a

131
00:05:21,600 --> 00:05:28,080
tool with natural language that saves

132
00:05:25,120 --> 00:05:30,000
him two days of work. Every day he makes

133
00:05:28,080 --> 00:05:33,919
a statement of work. And then listen to

134
00:05:30,000 --> 00:05:35,919
this. Someone got access to that tool

135
00:05:33,919 --> 00:05:38,160
and shared it across the other parks.

136
00:05:35,919 --> 00:05:40,400
There's about 430 parks in the service.

137
00:05:38,160 --> 00:05:42,560
The National Park Service is estimating

138
00:05:40,400 --> 00:05:44,639
that the tool that Adam built in 45

139
00:05:42,560 --> 00:05:48,400
minutes is going to save the service

140
00:05:44,639 --> 00:05:52,639
7,000 days of human labor this year.

141
00:05:48,400 --> 00:05:55,440
That's the kind of impact that normal

142
00:05:52,639 --> 00:05:58,240
professionals can have even without any

143
00:05:55,440 --> 00:06:02,560
technical ability if only they're given

144
00:05:58,240 --> 00:06:02,560
very basic foundational

145
00:06:03,720 --> 00:06:07,840
training. People are wanting to learn AI

146
00:06:06,240 --> 00:06:10,000
and how it can be transformative for

147
00:06:07,840 --> 00:06:13,120
their business but they don't have the

148
00:06:10,000 --> 00:06:15,039
basic language. And so while lots of

149
00:06:13,120 --> 00:06:16,960
organizations are asking me how can we

150
00:06:15,039 --> 00:06:18,800
work with AI to transform our business

151
00:06:16,960 --> 00:06:21,039
where I have to start with them is how

152
00:06:18,800 --> 00:06:23,039
do you work with AI? The research I'm

153
00:06:21,039 --> 00:06:26,479
familiar with suggests that while on the

154
00:06:23,039 --> 00:06:29,680
one hand AI makes people 25% faster and

155
00:06:26,479 --> 00:06:32,560
12% more work and 40% better quality.

156
00:06:29,680 --> 00:06:34,960
It's also true that less than 10% of

157
00:06:32,560 --> 00:06:36,720
working professionals are driving

158
00:06:34,960 --> 00:06:38,319
meaningful productivity gains from

159
00:06:36,720 --> 00:06:40,720
collaboration with AI. To me there's

160
00:06:38,319 --> 00:06:43,440
this enormous gap. I call it the

161
00:06:40,720 --> 00:06:46,080
realization gap. We conducted studies

162
00:06:43,440 --> 00:06:49,199
both in Europe and in the United States.

163
00:06:46,080 --> 00:06:50,960
And what we found is surprisingly AI

164
00:06:49,199 --> 00:06:53,120
didn't help most people be more

165
00:06:50,960 --> 00:06:55,680
creative. In fact, in many cases the

166
00:06:53,120 --> 00:06:57,680
people that we studied, AI made them

167
00:06:55,680 --> 00:06:59,759
less creative. And as we started digging

168
00:06:57,680 --> 00:07:01,759
into the research, we were surprised and

169
00:06:59,759 --> 00:07:04,160
looked at the data we were confused

170
00:07:01,759 --> 00:07:07,120
because you think AI should make people

171
00:07:04,160 --> 00:07:09,280
more creative, not less. And we studied

172
00:07:07,120 --> 00:07:12,560
the underperformers and then we studied

173
00:07:09,280 --> 00:07:14,639
the outperformers. And what we found is

174
00:07:12,560 --> 00:07:18,160
the outperformers had a fundamentally

175
00:07:14,639 --> 00:07:21,000
different orientation towards AI than

176
00:07:18,160 --> 00:07:24,319
the underperformers did. Whereas the

177
00:07:21,000 --> 00:07:27,120
underperformers treated AI like a tool,

178
00:07:24,319 --> 00:07:30,160
the outperformers treated AI like a

179
00:07:27,120 --> 00:07:33,280
teammate. And shifting your orientation

180
00:07:30,160 --> 00:07:35,759
from tool to teammate changes everything

181
00:07:33,280 --> 00:07:38,319
about the kinds of outcomes that you can

182
00:07:35,759 --> 00:07:40,960
achieve working with generative AI. A

183
00:07:38,319 --> 00:07:44,080
simple example is what do you do when it

184
00:07:40,960 --> 00:07:47,120
gives you mediocre results? If it's a

185
00:07:44,080 --> 00:07:49,599
tool, you get a mediocre result and then

186
00:07:47,120 --> 00:07:51,680
maybe you improve it or maybe you say,

187
00:07:49,599 --> 00:07:53,199
"Ah, it's no good at doing that." If

188
00:07:51,680 --> 00:07:55,440
it's a teammate who's given you a

189
00:07:53,199 --> 00:07:57,360
mediocre results, think about the last

190
00:07:55,440 --> 00:07:58,960
teammate who gave you work product that

191
00:07:57,360 --> 00:08:01,360
wasn't sufficient. You gave them

192
00:07:58,960 --> 00:08:03,680
feedback. You gave them coaching. You

193
00:08:01,360 --> 00:08:06,319
gave them mentorship. You helped them

194
00:08:03,680 --> 00:08:08,240
improve it. And so what we found is the

195
00:08:06,319 --> 00:08:10,639
people who treat AI like a teammate,

196
00:08:08,240 --> 00:08:12,680
coach it and give it feedback and

197
00:08:10,639 --> 00:08:15,039
importantly get it to ask them

198
00:08:12,680 --> 00:08:17,599
questions. The fundamental orientation a

199
00:08:15,039 --> 00:08:20,960
lot of people take towards AI is I'm the

200
00:08:17,599 --> 00:08:22,400
question asker. AI is the answer giver.

201
00:08:20,960 --> 00:08:25,039
But if you think about AI like a

202
00:08:22,400 --> 00:08:27,199
teammate, you say, "Hey, what are 10

203
00:08:25,039 --> 00:08:29,360
questions I should ask about this?" Or,

204
00:08:27,199 --> 00:08:31,680
"What do you need to know from me in

205
00:08:29,360 --> 00:08:33,760
order to get the best response?" So

206
00:08:31,680 --> 00:08:35,719
things, for example, like, "You have a

207
00:08:33,760 --> 00:08:37,680
difficult conversation coming up with a

208
00:08:35,719 --> 00:08:39,279
coworker." Did you know you could

209
00:08:37,680 --> 00:08:42,000
leverage a large language model to

210
00:08:39,279 --> 00:08:44,320
roleplay that conversation? You can get

211
00:08:42,000 --> 00:08:46,560
an AI to interview you about your

212
00:08:44,320 --> 00:08:48,560
conversation partner and then construct

213
00:08:46,560 --> 00:08:50,560
a psychological profile of your

214
00:08:48,560 --> 00:08:52,800
conversation partner and then play the

215
00:08:50,560 --> 00:08:54,720
role of your conversation partner in a

216
00:08:52,800 --> 00:08:56,240
role play and then give you feedback

217
00:08:54,720 --> 00:08:58,320
from the perspective of your

218
00:08:56,240 --> 00:08:59,080
conversation partner on how you approach

219
00:08:58,320 --> 00:09:01,040
the

220
00:08:59,080 --> 00:09:03,839
conversation. That's something you can

221
00:09:01,040 --> 00:09:05,680
do today. And there are many things like

222
00:09:03,839 --> 00:09:07,680
that. I call them drills, but there are

223
00:09:05,680 --> 00:09:11,519
many things like that where if someone

224
00:09:07,680 --> 00:09:14,000
will just shift their consideration set

225
00:09:11,519 --> 00:09:16,480
of what are the things I can do with AI,

226
00:09:14,000 --> 00:09:18,240
they end up discovering applications

227
00:09:16,480 --> 00:09:20,320
that I've never even dreamed of. I've

228
00:09:18,240 --> 00:09:22,160
been doing this stuff for 2 years and my

229
00:09:20,320 --> 00:09:24,800
students are regularly coming to me with

230
00:09:22,160 --> 00:09:26,800
use cases I've never imagined that

231
00:09:24,800 --> 00:09:28,480
landed them in a destination I could

232
00:09:26,800 --> 00:09:30,800
have never predicted and they could

233
00:09:28,480 --> 00:09:32,640
never have predicted.

234
00:09:30,800 --> 00:09:35,440
For me, I never thought about myself as

235
00:09:32,640 --> 00:09:37,600
a creative individual. Now, I fully and

236
00:09:35,440 --> 00:09:40,800
fundamentally believe every single human

237
00:09:37,600 --> 00:09:42,399
being has innate creative capacity.

238
00:09:40,800 --> 00:09:45,240
Every single one of us. What the D

239
00:09:42,399 --> 00:09:47,680
school has helped me do is unlock

240
00:09:45,240 --> 00:09:50,080
others. Everyone has this latent

241
00:09:47,680 --> 00:09:52,399
creative capacity. Once I was teaching a

242
00:09:50,080 --> 00:09:54,399
class with a hip-hop artist named LRA.

243
00:09:52,399 --> 00:09:55,839
He's a multi-time Grammy award-winning

244
00:09:54,399 --> 00:09:57,920
artist. And he and I are teaching a

245
00:09:55,839 --> 00:09:59,519
class to graduate students at Stanford.

246
00:09:57,920 --> 00:10:01,200
and we're giving them the assignment,

247
00:09:59,519 --> 00:10:03,519
you've got to go get inspiration in the

248
00:10:01,200 --> 00:10:05,120
world. And what I can see is it's like

249
00:10:03,519 --> 00:10:06,800
looking at myself in the mirror 10 years

250
00:10:05,120 --> 00:10:09,640
ago because all of the business school

251
00:10:06,800 --> 00:10:13,279
students in the class are going

252
00:10:09,640 --> 00:10:15,360
inspiration and I just felt LRae is

253
00:10:13,279 --> 00:10:17,720
clearly the creative legend in the room.

254
00:10:15,360 --> 00:10:19,839
I said, "Lae, what do you think about

255
00:10:17,720 --> 00:10:21,360
inspiration?" And of course, as only a

256
00:10:19,839 --> 00:10:23,200
hip-hop artist could do, he dropped a

257
00:10:21,360 --> 00:10:24,880
bar. He said, "Inspiration's a

258
00:10:23,200 --> 00:10:27,200
discipline."

259
00:10:24,880 --> 00:10:29,839
And I realized in that moment for these

260
00:10:27,200 --> 00:10:33,200
students, it's not even on their radar

261
00:10:29,839 --> 00:10:35,440
as a tool, let alone a routine part of

262
00:10:33,200 --> 00:10:38,800
their life. But the most wildly creative

263
00:10:35,440 --> 00:10:40,959
individuals I know are disciplined about

264
00:10:38,800 --> 00:10:42,720
cultivating the inputs to their thinking

265
00:10:40,959 --> 00:10:44,399
because they know it affects the outputs

266
00:10:42,720 --> 00:10:47,760
of their thinking. And so even in

267
00:10:44,399 --> 00:10:49,519
regards to AI, I push people, what is

268
00:10:47,760 --> 00:10:51,600
the inspiration you're bringing to the

269
00:10:49,519 --> 00:10:54,079
model? Everybody has the same access to

270
00:10:51,600 --> 00:10:55,839
the same chat GPT. How do I get a

271
00:10:54,079 --> 00:10:57,519
different output than you do? It's

272
00:10:55,839 --> 00:10:59,360
because of what I bring to the model.

273
00:10:57,519 --> 00:11:01,680
And what do I bring to the model?

274
00:10:59,360 --> 00:11:04,000
Certainly, I bring technique, but I also

275
00:11:01,680 --> 00:11:06,240
bring my experience. I bring my

276
00:11:04,000 --> 00:11:08,399
perspective. I bring all the inspiration

277
00:11:06,240 --> 00:11:12,640
I've gleaned from the world. That's what

278
00:11:08,399 --> 00:11:12,640
gets a user a differential output from a

279
00:11:13,880 --> 00:11:18,880
model. A seventh grader in Ohio, who I

280
00:11:17,120 --> 00:11:20,399
don't even know what her name is, but

281
00:11:18,880 --> 00:11:21,920
her teacher asked, "What is creativity?"

282
00:11:20,399 --> 00:11:24,160
and she put a post-it note up on the

283
00:11:21,920 --> 00:11:26,440
board that says, "Creativity is doing

284
00:11:24,160 --> 00:11:29,279
more than the first thing you think

285
00:11:26,440 --> 00:11:32,000
of." And that's my favorite definition

286
00:11:29,279 --> 00:11:34,480
because it speaks to a profound

287
00:11:32,000 --> 00:11:36,320
cognitive bias that we hold. It's been

288
00:11:34,480 --> 00:11:38,240
called functional fixedness. It's been

289
00:11:36,320 --> 00:11:42,320
called the Einsteining effect. But the

290
00:11:38,240 --> 00:11:45,600
basic premise is humans tend to fixate

291
00:11:42,320 --> 00:11:48,160
on an early solution and be satisfied.

292
00:11:45,600 --> 00:11:49,600
Herbert Simon called it satisficing. But

293
00:11:48,160 --> 00:11:52,079
it's the idea that if we get to good

294
00:11:49,600 --> 00:11:54,160
enough, it's enough. And that's why I

295
00:11:52,079 --> 00:11:55,760
love that seventh grader's definition.

296
00:11:54,160 --> 00:11:58,399
Creativity is doing more than the first

297
00:11:55,760 --> 00:12:00,800
thing you think of. It's pushing past

298
00:11:58,399 --> 00:12:03,680
good enough. Is the definition of

299
00:12:00,800 --> 00:12:07,440
creativity changing in the age of AI? I

300
00:12:03,680 --> 00:12:09,920
don't think so. The reality is with AI,

301
00:12:07,440 --> 00:12:12,160
it's now easier than ever to get good

302
00:12:09,920 --> 00:12:14,320
enough. If your goal is world class, if

303
00:12:12,160 --> 00:12:16,240
your goal is exceptional, then what you

304
00:12:14,320 --> 00:12:19,600
want to be prompting for is actually

305
00:12:16,240 --> 00:12:23,120
volume and variation. And that takes

306
00:12:19,600 --> 00:12:24,959
time. It takes time to not only read

307
00:12:23,120 --> 00:12:27,680
through it, but to sort it and to

308
00:12:24,959 --> 00:12:29,200
process it. But fundamentally, the

309
00:12:27,680 --> 00:12:31,440
definition of creativity doesn't change

310
00:12:29,200 --> 00:12:34,480
in the age of AI. It's just that the

311
00:12:31,440 --> 00:12:37,440
human's ability or inability to arrive

312
00:12:34,480 --> 00:12:40,800
at a creative state is affected not only

313
00:12:37,440 --> 00:12:44,399
by the technology but also by their

314
00:12:40,800 --> 00:12:46,720
stated or unstated objectives in

315
00:12:44,399 --> 00:12:48,800
collaborating with it. Creators don't

316
00:12:46,720 --> 00:12:50,959
need to be afraid of AI. Creators need

317
00:12:48,800 --> 00:12:53,200
to dive in. They need to lean in.

318
00:12:50,959 --> 00:12:55,760
Creators are about to be unleashed in a

319
00:12:53,200 --> 00:12:58,000
way they've never been unleashed before.

320
00:12:55,760 --> 00:13:02,639
The only correct answer to the question

321
00:12:58,000 --> 00:13:05,440
how do you use AI is I don't I don't use

322
00:13:02,639 --> 00:13:07,600
AI I work with it. When you start

323
00:13:05,440 --> 00:13:10,600
working with AI, it will change

324
00:13:07,600 --> 00:13:10,600
everything.

